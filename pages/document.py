import streamlit as st
import pandas as pd
import re
from datetime import datetime
from zoneinfo import ZoneInfo
from openai import OpenAI
from data import dummy_data_management as dummy
import fitz  # PyMuPDF
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

st.set_page_config(page_title="ë¬¸ì„œ ê´€ë¦¬", layout="wide")

# âœ… API í‚¤ í™•ì¸
if "api_key" not in st.session_state or not st.session_state.api_key:
    st.error("âŒ í™ˆ í™”ë©´ì—ì„œ OpenAI API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    st.stop()

# âœ… ë¬¸ì„œ ë°ì´í„°í”„ë ˆì„ ì´ˆê¸°í™”
if 'documents' not in st.session_state:
    st.session_state.documents = pd.DataFrame(columns=[
        "ì œëª©", "íŒŒì¼ëª…", "ì—…ë¡œë”", "ë“±ë¡ì¼", "íŒŒì¼ë°ì´í„°", "ìš”ì•½", "ì„ë² ë”©"
    ])

# âœ… ë²„ì „ ìˆëŠ” íŒŒì¼ëª… ìƒì„±

def get_versioned_filename(filename):
    name, ext = re.match(r"(.+?)(\.[^.]+)?$", filename).groups()
    ext = ext or ""
    existing = st.session_state.documents["íŒŒì¼ëª…"].tolist()
    pattern = re.compile(f"{re.escape(name)}(?:_v(\\d+)){re.escape(ext)}")
    versions = [int(m.group(1)) for f in existing if (m := pattern.match(f))]
    if filename in existing:
        versions.append(0)
    new_version = max(versions) + 1 if versions else None
    return filename if new_version is None else f"{name}_v{new_version}{ext}"

# âœ… GPT ìš”ì•½ ë° ì„ë² ë”© í•¨ìˆ˜
@st.cache_data(show_spinner=False)
def summarize_and_embed_with_gpt(title, text):
    try:
        client = OpenAI(api_key=st.session_state.api_key)
        summary_resp = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ERP ê¸°ì—… ë¬¸ì„œ ìš”ì•½ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”."},
                {"role": "user", "content": text[:6000]}
            ],
            temperature=0.3
        )
        summary = summary_resp.choices[0].message.content.strip()
        embedding_input = f"{title}\n\n{text}"
        emb_resp = client.embeddings.create(
            model="text-embedding-3-small",
            input=embedding_input
        )
        embedding = emb_resp.data[0].embedding
        return summary, embedding
    except Exception as e:
        return f"ìš”ì•½ ì‹¤íŒ¨: {e}", []

# âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_text_from_pdf(file_bytes):
    try:
        pdf = fitz.open(stream=file_bytes, filetype="pdf")
        return "\n".join(page.get_text() for page in pdf)
    except Exception:
        return ""

# âœ… íƒ€ì´í‹€
st.title("ğŸ“š ë¬¸ì„œ ë“±ë¡ ë° ê³µìœ ")

# âœ… ë¬¸ì„œ ì—…ë¡œë“œ í¼
with st.form("upload_form", clear_on_submit=True):
    st.subheader("ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("íŒŒì¼ ì„ íƒ", type=["pdf", "docx", "xlsx", "png", "jpg", "txt"])
    uploader = st.selectbox("ë‹´ë‹¹ì ì„ íƒ", dummy.employees_df["name"].tolist())
    submitted = st.form_submit_button("ì—…ë¡œë“œ")

    if submitted and uploaded_file and uploader:
        filename = get_versioned_filename(uploaded_file.name)
        title = uploaded_file.name.rsplit('.', 1)[0]  # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•œ ê²ƒ

        now_kst = datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M")
        file_bytes = uploaded_file.getvalue()

        if filename.lower().endswith(".pdf"):
            text = extract_text_from_pdf(file_bytes)
            summary, embedding = summarize_and_embed_with_gpt(title, text)
        else:
            summary, embedding = "(ìš”ì•½ì€ PDF ë¬¸ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤)", []

        new_doc = pd.DataFrame([{
            "ì œëª©": title,
            "íŒŒì¼ëª…": filename,
            "ì—…ë¡œë”": uploader,
            "ë“±ë¡ì¼": now_kst,
            "íŒŒì¼ë°ì´í„°": file_bytes,
            "ìš”ì•½": summary,
            "ì„ë² ë”©": embedding
        }])
        st.session_state.documents = pd.concat([st.session_state.documents, new_doc], ignore_index=True)
        st.success(f"âœ… ë¬¸ì„œ ì—…ë¡œë“œ ë° ìš”ì•½ ì™„ë£Œ: {filename}")

# âœ… ê²€ìƒ‰ ì…ë ¥
col1, col2 = st.columns(2)
with col1:
    search = st.text_input("ë¬¸ì„œ ì œëª© ë˜ëŠ” ë‹´ë‹¹ì ê²€ìƒ‰")
with col2:
    gpt_query = st.text_input("ğŸ’¡ GPT ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ì–´ ì…ë ¥")

# âœ… ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ ìŠ¬ë¼ì´ë”
st.markdown("### ğŸ¯ GPT ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ ì¡°ì ˆ")
col1, col2, col3 = st.columns([2, 6, 2])
with col1:
    st.caption("ì œëª© ìœ ì‚¬ë„")
with col3:
    st.caption("ë³¸ë¬¸ ìœ ì‚¬ë„")
with col2:
    title_weight = st.slider(
        label="ê°€ì¤‘ì¹˜ ìŠ¬ë¼ì´ë”",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        format="%.2f",
        label_visibility="collapsed"
    )
st.caption(f"ğŸ“Œ í˜„ì¬ ê°€ì¤‘ì¹˜ â†’ ì œëª©: **{title_weight:.2f}**, ë³¸ë¬¸: **{1 - title_weight:.2f}**")

# âœ… í•„í„°ë§ ì„¤ì •
col1, col2 = st.columns(2)
with col1:
    ext_filter = st.selectbox("í™•ì¥ì í•„í„°", ["ì „ì²´", "pdf", "docx", "xlsx", "png", "jpg", "txt"])
with col2:
    sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ë“±ë¡ì¼", "ì œëª©", "ì—…ë¡œë”"])
sort_order = st.radio("ì •ë ¬ ìˆœì„œ", ["ë‚´ë¦¼ì°¨ìˆœ", "ì˜¤ë¦„ì°¨ìˆœ"], horizontal=True)

# âœ… ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
filtered_docs = st.session_state.documents.copy()

if search:
    filtered_docs = filtered_docs[filtered_docs.apply(
        lambda r: search.lower() in r["ì œëª©"].lower() or search.lower() in r["ì—…ë¡œë”"].lower(), axis=1
    )]

if gpt_query:
    try:
        client = OpenAI(api_key=st.session_state.api_key)
        query_emb = client.embeddings.create(
            model="text-embedding-3-small",
            input=gpt_query
        ).data[0].embedding

        similarities = []
        for idx, row in filtered_docs.iterrows():
            if row["ì„ë² ë”©"]:
                title_emb_input = f"{row['ì œëª©']}"
                full_emb_input = f"{row['ì œëª©']}\n\n{text if 'text' in locals() else ''}"
                doc_emb = np.array(row["ì„ë² ë”©"])
                sim = cosine_similarity([query_emb], [doc_emb])[0][0]
                similarities.append(sim)
            else:
                similarities.append(0.0)

        filtered_docs["ìœ ì‚¬ë„"] = similarities
        filtered_docs = filtered_docs.sort_values(by="ìœ ì‚¬ë„", ascending=False)
    except Exception as e:
        st.warning(f"GPT ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
else:
    if ext_filter != "ì „ì²´":
        filtered_docs = filtered_docs[filtered_docs["íŒŒì¼ëª…"].str.lower().str.endswith(ext_filter)]
    filtered_docs = filtered_docs.sort_values(by=sort_by, ascending=(sort_order == "ì˜¤ë¦„ì°¨ìˆœ")).reset_index(drop=True)

# âœ… ë¬¸ì„œ ëª©ë¡ ì¶œë ¥
st.markdown(f"**ì´ ë¬¸ì„œ ìˆ˜: {len(filtered_docs)}ê°œ**")
if filtered_docs.empty:
    st.info("ë“±ë¡ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    for idx, row in filtered_docs.iterrows():
        with st.expander(f"ğŸ“„ {row['ì œëª©']}" + (f" (ìœ ì‚¬ë„: {row['ìœ ì‚¬ë„']:.2f})" if "ìœ ì‚¬ë„" in row else "")):
            st.caption(f"ì—…ë¡œë”: {row['ì—…ë¡œë”']} | ë“±ë¡ì¼: {row['ë“±ë¡ì¼']}")
            st.download_button("â¬‡ï¸ ë‹¤ìš´ë¡œë“œ", row["íŒŒì¼ë°ì´í„°"], file_name=row["íŒŒì¼ëª…"], mime="application/octet-stream", key=f"down_{idx}")
            if row["ìš”ì•½"]:
                st.markdown("**ğŸ“Œ ìš”ì•½:**")
                st.info(row["ìš”ì•½"])
            if row["ì„ë² ë”©"]:
                if st.button("ğŸ” ì„ë² ë”© ë³´ê¸°", key=f"embed_btn_{idx}"):
                    st.json(row["ì„ë² ë”©"])
            col1, col2 = st.columns([3,1])
            with col1:
                delete_input = st.text_input("ì‚­ì œí•˜ë ¤ë©´ 'ì‚­ì œ' ì…ë ¥", key=f"del_in_{idx}", label_visibility="collapsed", placeholder="ì‚­ì œ")
            with col2:
                if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"del_btn_{idx}"):
                    if delete_input.strip() == "ì‚­ì œ":
                        st.session_state.documents = st.session_state.documents.drop(index=idx).reset_index(drop=True)
                        st.success(f"âœ… '{row['ì œëª©']}' ì‚­ì œ ì™„ë£Œ")
                        st.rerun()
                    else:
                        st.warning("â— 'ì‚­ì œ'ë¼ê³  ì…ë ¥í•´ì•¼ ì‚­ì œë©ë‹ˆë‹¤.")
