import streamlit as st
import pandas as pd
import re
from datetime import datetime
from zoneinfo import ZoneInfo
from openai import OpenAI
from data import dummy_data_management as dummy  # âœ… ì§ì› ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
import fitz  # PyMuPDF
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# âœ… ê°€ì¥ ë¨¼ì € í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¬¸ì„œ ê´€ë¦¬", layout="wide")

# ë¬¸ì„œ ë° ì„ë² ë”© ë°ì´í„° ì´ˆê¸°í™”
if 'documents' not in st.session_state:
    st.session_state.documents = pd.DataFrame(columns=[
        "ì œëª©", "íŒŒì¼ëª…", "ì—…ë¡œë”", "ë“±ë¡ì¼", "íŒŒì¼ë°ì´í„°", "ìš”ì•½", "ì„ë² ë”©"
    ])

# âœ… í™ˆì—ì„œ ì…ë ¥ëœ API í‚¤ ì‚¬ìš© (chat.pyì™€ ë™ì¼í•˜ê²Œ ì—°ë™ë¨)
if "api_key" not in st.session_state or not st.session_state.api_key:
    st.error("âŒ í™ˆ í™”ë©´ì—ì„œ OpenAI API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    st.stop()

# ë²„ì „ ìˆëŠ” íŒŒì¼ëª… ìƒì„± í•¨ìˆ˜
def get_versioned_filename(filename):
    name, ext = re.match(r"(.+?)(\.[^.]+)?$", filename).groups()
    ext = ext or ""
    existing = st.session_state.documents["íŒŒì¼ëª…"].tolist()
    pattern = re.compile(f"{re.escape(name)}(?:_v(\\d+)){re.escape(ext)}")
    versions = [int(m.group(1)) for f in existing if (m := pattern.match(f))]
    if filename in existing:
        versions.append(0)
    new_version = max(versions) + 1 if versions else None
    return filename if new_version is None else f"{name}_v{new_version}{ext}"

# GPT ìš”ì•½ ë° ì„ë² ë”© í•¨ìˆ˜
@st.cache_data(show_spinner=False)
def summarize_and_embed_with_gpt(text):
    try:
        client = OpenAI(api_key=st.session_state.api_key)
        response = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ERP ê¸°ì—… ë¬¸ì„œ ìš”ì•½ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”."},
                {"role": "user", "content": text[:6000]}
            ],
            temperature=0.3
        )
        summary = response.choices[0].message.content.strip()

        embedding_response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text[:8191]
        )
        embedding = embedding_response.data[0].embedding
        return summary, embedding
    except Exception as e:
        return f"ìš”ì•½ ì‹¤íŒ¨: {e}", []

# PDF â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_pdf(file_bytes):
    try:
        pdf = fitz.open(stream=file_bytes, filetype="pdf")
        return "\n".join(page.get_text() for page in pdf)
    except Exception:
        return ""

# íƒ€ì´í‹€ ë° ì—…ë¡œë“œ í¼
st.title("ğŸ“š ë¬¸ì„œ ë“±ë¡ ë° ê³µìœ ")

uploaded_file = None
with st.form("upload_form", clear_on_submit=True):
    st.subheader("ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("íŒŒì¼ ì„ íƒ", type=["pdf", "docx", "xlsx", "png", "jpg", "txt"])
    title = st.text_input("ë¬¸ì„œ ì œëª©", value=uploaded_file.name if uploaded_file else "")
    uploader_names = dummy.employees_df["name"].tolist()
    uploader = st.selectbox("ë‹´ë‹¹ì ì„ íƒ", uploader_names)
    submitted = st.form_submit_button("ì—…ë¡œë“œ")

    if submitted:
        if not title or not uploader or not uploaded_file:
            st.warning("ëª¨ë“  í•­ëª©ì„ ì…ë ¥í•˜ê³  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            filename = get_versioned_filename(uploaded_file.name)
            now_kst = datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M")
            file_bytes = uploaded_file.getvalue()

            if filename.lower().endswith(".pdf"):
                text = extract_text_from_pdf(file_bytes)
                summary, embedding = summarize_and_embed_with_gpt(text)
            else:
                summary, embedding = "(ìš”ì•½ì€ PDF ë¬¸ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤)", []

            new_doc = pd.DataFrame([{
                "ì œëª©": title,
                "íŒŒì¼ëª…": filename,
                "ì—…ë¡œë”": uploader,
                "ë“±ë¡ì¼": now_kst,
                "íŒŒì¼ë°ì´í„°": file_bytes,
                "ìš”ì•½": summary,
                "ì„ë² ë”©": embedding
            }])
            st.session_state.documents = pd.concat([st.session_state.documents, new_doc], ignore_index=True)
            st.success(f"âœ… ë¬¸ì„œ ì—…ë¡œë“œ ë° ìš”ì•½ ì™„ë£Œ: {filename}")
            uploaded_file = None

# GPT ê¸°ë°˜ ê²€ìƒ‰ì–´ ì…ë ¥
st.subheader("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ë° ê´€ë¦¬")
gpt_query = st.text_input("ğŸ’¡ GPT ê¸°ë°˜ ê²€ìƒ‰ì–´ ì…ë ¥")

# ê²€ìƒ‰ ì„ë² ë”© ìƒì„± ë° ìœ ì‚¬ë„ ê³„ì‚°
docs = st.session_state.documents.copy()
if gpt_query:
    try:
        client = OpenAI(api_key=st.session_state.api_key)
        query_embedding = client.embeddings.create(
            model="text-embedding-3-small",
            input=gpt_query
        ).data[0].embedding

        doc_embeddings = docs["ì„ë² ë”©"].tolist()
        similarities = []
        for emb in doc_embeddings:
            if emb:
                sim = cosine_similarity([query_embedding], [emb])[0][0]
                similarities.append(sim)
            else:
                similarities.append(0.0)
        docs["ìœ ì‚¬ë„"] = similarities
        docs = docs.sort_values(by="ìœ ì‚¬ë„", ascending=False)
    except Exception as e:
        st.warning(f"ê²€ìƒ‰ ì„ë² ë”© ì‹¤íŒ¨: {e}")

# ë¬¸ì„œ ëª©ë¡ ì¶œë ¥
st.markdown(f"**ì´ ë¬¸ì„œ ìˆ˜: {len(docs)}ê°œ**")
if docs.empty:
    st.info("ë“±ë¡ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    for idx, row in docs.iterrows():
        with st.expander(f"ğŸ“„ {row['ì œëª©']}" + (f" (ìœ ì‚¬ë„: {row['ìœ ì‚¬ë„']:.2f})" if "ìœ ì‚¬ë„" in row else "")):
            st.caption(f"ì—…ë¡œë”: {row['ì—…ë¡œë”']} | ë“±ë¡ì¼: {row['ë“±ë¡ì¼']}")
            st.download_button(
                "â¬‡ï¸ ë‹¤ìš´ë¡œë“œ",
                data=row["íŒŒì¼ë°ì´í„°"],
                file_name=row["íŒŒì¼ëª…"],
                mime="application/octet-stream",
                key=f"download_{idx}"
            )
            if row.get("ìš”ì•½"):
                st.markdown("**ğŸ“Œ ìš”ì•½ ë‚´ìš©:**")
                st.info(row["ìš”ì•½"])

            if row.get("ì„ë² ë”©"):
                if st.button("ğŸ” ì„ë² ë”© ê°’ ë³´ê¸°", key=f"embedding_btn_{idx}"):
                    st.json(row["ì„ë² ë”©"], expanded=False)

            col1, col2 = st.columns([3, 1])
            with col1:
                delete_input = st.text_input(
                    f"'{row['ì œëª©']}' ì‚­ì œ í™•ì¸ìš© ì…ë ¥",
                    key=f"delete_input_{idx}",
                    label_visibility="collapsed",
                    placeholder="ì‚­ì œ"
                )
            with col2:
                if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_btn_{idx}"):
                    if delete_input.strip() == "ì‚­ì œ":
                        st.session_state.documents = st.session_state.documents.drop(index=idx).reset_index(drop=True)
                        st.success(f"âœ… '{row['ì œëª©']}' ë¬¸ì„œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                    else:
                        st.warning("â— ì‚­ì œí•˜ë ¤ë©´ 'ì‚­ì œ'ë¼ê³  ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            st.markdown("---")
